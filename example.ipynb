{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7QcUBoBMSyY"
      },
      "source": [
        "This notbook (almost) replicates Figure 4a presented in the paper \"*Amplified Early Stopping Bias: Overestimated Performance with Deep Learning*\" as an example. Specifically, we run the code to train a multi-layer Perceptron on random Gaussian vectors for multiple network depth, training sample sizes, and input feutere sizes.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIT3_2ZNMSyZ"
      },
      "source": [
        "Run the code below if you are using Google Colab (or probably also on other cloud services)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhgYi2VkMSyZ"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/NonaRjb/DeepOverestimation.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd DeepOverestimation\n",
        "%pwd"
      ],
      "metadata": {
        "id": "2QDD1I0Mb4mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgOTH20zMSya"
      },
      "outputs": [],
      "source": [
        "# Install a pip package in the current Jupyter kernel\n",
        "import sys\n",
        "!{sys.executable} -m pip install mat73\n",
        "!{sys.executable} -m pip install mne\n",
        "!{sys.executable} -m pip install torchmetrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bG39FE2nMSya"
      },
      "source": [
        "## The original values\n",
        "In the original experiment that results in the numbers presented in Fig. 4a, we used the following values for different inputs to the Python program:\n",
        "\n",
        "1. **D (input feature size):** d_array = (4 8 16 32 64 128 256 512)\n",
        "2. **N (number of training samples):** n_array = (50 100 200 400 800 1600 3200)\n",
        "3. **L (network depth):** l_array = (1 4 32 64)\n",
        "4. **H (network width):** 16\n",
        "5. **O (optimizer):** AdamW\n",
        "\n",
        "Also we used a batch size of 16 and a learning rate of 0.0001. The total number of epochs was at most 500."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyTA3rvmMSya"
      },
      "source": [
        "## What we run here\n",
        "As using all the list values from the above list takes a long time to run, we will use a smaller list to test the code. Specifically, we will run the code with:\n",
        "1. **D:** d_array = (8 16 32 64)\n",
        "2. **N:** n_array = (50 100 200 400 800)\n",
        "3. **L:** l_array = (1 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVZFAPSMMSya"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "\n",
        "# Define your lists of variables\n",
        "list_l = [1, 32]\n",
        "list_n = [50, 100, 200, 400, 800]\n",
        "list_d = [8, 16, 32, 64]\n",
        "\n",
        "# Iterate over all combinations of $l, $n, and $d\n",
        "for l, n, d in itertools.product(list_l, list_n, list_d):\n",
        "    print(f\"Running command with l={l}, n={n}, d={d}\")\n",
        "    command = f\"python3 train_random.py -b 16 --lr 0.0001 --epochs 500 --hidden_size 16 -l {l} -n {n} --n_test 5000 -d {d} -r 2 --optim adamw --seed 42 --save_path ./out/ --experiment N1000_dnl\"\n",
        "    print(f\"Running: {command}\")\n",
        "    !{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization\n",
        "\n",
        "To visualize the results, we use the visualization code in `data_analysis/visualize_results.py`."
      ],
      "metadata": {
        "id": "6op5g7nrcVpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run data_analysis/visualize_results.py -x \"n\" -y \"l\" --y_vals 1 32 --experiment \"H16_dnl\" --task \"line_plot_average\" --root_path \"./out/\""
      ],
      "metadata": {
        "id": "jaRXyWyRcrDn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}