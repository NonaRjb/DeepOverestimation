{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7QcUBoBMSyY"
      },
      "source": [
        "This notbook (almost) replicates Figure 4a presented in the paper \"*Amplified Early Stopping Bias: Overestimated Performance with Deep Learning*\" as an example. Specifically, we run the code to train a multi-layer Perceptron on random Gaussian vectors for multiple network depth, training sample sizes, and input feutere sizes.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIT3_2ZNMSyZ"
      },
      "source": [
        "Run the code below if you are using Google Colab (or probably also on other cloud services)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FhgYi2VkMSyZ",
        "outputId": "9249dd15-2c7c-4cb3-f653-adb37010ccda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'DeepOverestimation' already exists and is not an empty directory.\n",
            "/content/DeepOverestimation\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/DeepOverestimation'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!git clone https://github.com/NonaRjb/DeepOverestimation.git\n",
        "%cd DeepOverestimation\n",
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wgOTH20zMSya",
        "outputId": "66cefa92-7e19-44f1-c49d-c97b14a22628",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mat73 in /usr/local/lib/python3.10/dist-packages (0.65)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from mat73) (3.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mat73) (1.26.4)\n",
            "Requirement already satisfied: mne in /usr/local/lib/python3.10/dist-packages (1.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.4)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.10/dist-packages (from mne) (3.7.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from mne) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (24.1)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from mne) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.66.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2024.8.30)\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.5.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy<2.0,>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.5.0+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.8-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (3.0.2)\n",
            "Downloading torchmetrics-1.5.1-py3-none-any.whl (890 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.6/890.6 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.8-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.8 torchmetrics-1.5.1\n"
          ]
        }
      ],
      "source": [
        "# Install a pip package in the current Jupyter kernel\n",
        "import sys\n",
        "!{sys.executable} -m pip install mat73\n",
        "!{sys.executable} -m pip install mne\n",
        "!{sys.executable} -m pip install torchmetrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bG39FE2nMSya"
      },
      "source": [
        "## The original values\n",
        "In the original experiment that results in the numbers presented in Fig. 4a, we used the following values for different inputs to the Python program:\n",
        "\n",
        "1. **D (input feature size):** d_array = (4 8 16 32 64 128 256 512)\n",
        "2. **N (number of training samples):** n_array = (50 100 200 400 800 1600 3200)\n",
        "3. **L (network depth):** l_array = (1 4 32 64)\n",
        "4. **H (network width):** 16\n",
        "5. **O (optimizer):** AdamW\n",
        "\n",
        "Also we used a batch size of 16 and a learning rate of 0.0001. The total number of epochs was at most 500."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyTA3rvmMSya"
      },
      "source": [
        "## What we run here\n",
        "As using all the list values from the above list takes a long time to run, we will use a smaller list to test the code. Specifically, we will run the code with:\n",
        "1. **D:** d_array = (8 16 32 64)\n",
        "2. **N:** n_array = (50 100 200 400 800)\n",
        "3. **L:** l_array = (1 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVZFAPSMMSya",
        "outputId": "c5e2ea13-0d4c-434f-9bab-d1c94f874ee4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running command with l=1, n=50, d=8\n",
            "Running: python3 train_random.py -b 16 --lr 0.0001 --epochs 500 --hidden_size 16 -l 1 -n 50 --n_test 5000 -d 8 -r 2 --optim adamw --seed 42 --save_path ./out/ --experiment N1000_dnl\n",
            "device:  cuda\n",
            "best epoch = 499\n",
            "Train Loss = 0.6434607803821564, Train ROC-AUC = 0.75\n",
            "Val Loss = 0.6659126281738281, Val ROC-AUC = 0.5\n",
            "Test Loss = 0.7630192161368105, Test ROC-AUC = 0.498751699924469\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.6517908573150635, Train ROC-AUC = 0.6761133670806885\n",
            "Val Loss = 0.694635272026062, Val ROC-AUC = 0.6666666865348816\n",
            "Test Loss = 0.7294797962085127, Test ROC-AUC = 0.49832502007484436\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.6461367905139923, Train ROC-AUC = 0.591093122959137\n",
            "Val Loss = 0.6334357261657715, Val ROC-AUC = 0.6666666865348816\n",
            "Test Loss = 0.7095257243790185, Test ROC-AUC = 0.5004978775978088\n",
            "\n",
            "best epoch = 494\n",
            "Train Loss = 0.6313289105892181, Train ROC-AUC = 0.612500011920929\n",
            "Val Loss = 0.6464171409606934, Val ROC-AUC = 0.8333333730697632\n",
            "Test Loss = 0.7086332866939874, Test ROC-AUC = 0.5042913556098938\n",
            "\n",
            "best epoch = 231\n",
            "Train Loss = 0.6120782196521759, Train ROC-AUC = 0.6709956526756287\n",
            "Val Loss = 0.5814208984375, Val ROC-AUC = 1.0\n",
            "Test Loss = 0.7283209337594029, Test ROC-AUC = 0.5128259658813477\n",
            "\n",
            "best epoch = 361\n",
            "Train Loss = 0.6360176801681519, Train ROC-AUC = 0.6230158805847168\n",
            "Val Loss = 0.5885022878646851, Val ROC-AUC = 0.8333333730697632\n",
            "Test Loss = 0.7342293681428075, Test ROC-AUC = 0.48786914348602295\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.5847790241241455, Train ROC-AUC = 0.7878787517547607\n",
            "Val Loss = 0.6537362337112427, Val ROC-AUC = 0.6666666865348816\n",
            "Test Loss = 0.7480895976289011, Test ROC-AUC = 0.5017623901367188\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.6553241610527039, Train ROC-AUC = 0.6865079402923584\n",
            "Val Loss = 0.6191032528877258, Val ROC-AUC = 0.6666666865348816\n",
            "Test Loss = 0.7267459832822172, Test ROC-AUC = 0.49639907479286194\n",
            "\n",
            "best epoch = 128\n",
            "Train Loss = 0.6201541721820831, Train ROC-AUC = 0.7791666984558105\n",
            "Val Loss = 0.7316511869430542, Val ROC-AUC = 0.5\n",
            "Test Loss = 0.717177141779147, Test ROC-AUC = 0.499579519033432\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.6483214497566223, Train ROC-AUC = 0.692307710647583\n",
            "Val Loss = 0.6617166996002197, Val ROC-AUC = 0.6666666865348816\n",
            "Test Loss = 0.7132096673353031, Test ROC-AUC = 0.49825650453567505\n",
            "\n",
            "best epoch = 495\n",
            "Train Loss = 0.6498473882675171, Train ROC-AUC = 0.6507936716079712\n",
            "Val Loss = 0.574787437915802, Val ROC-AUC = 1.0\n",
            "Test Loss = 0.7281614374428892, Test ROC-AUC = 0.4947914481163025\n",
            "\n",
            "best epoch = 246\n",
            "Train Loss = 0.670922726392746, Train ROC-AUC = 0.6230158805847168\n",
            "Val Loss = 0.6808371543884277, Val ROC-AUC = 0.5\n",
            "Test Loss = 0.6971563533091316, Test ROC-AUC = 0.5113077163696289\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.6404593884944916, Train ROC-AUC = 0.696969747543335\n",
            "Val Loss = 0.6666280627250671, Val ROC-AUC = 0.5\n",
            "Test Loss = 0.7081954448748702, Test ROC-AUC = 0.5110607147216797\n",
            "\n",
            "best epoch = 496\n",
            "Train Loss = 0.6527151763439178, Train ROC-AUC = 0.5590909123420715\n",
            "Val Loss = 0.629912793636322, Val ROC-AUC = 1.0\n",
            "Test Loss = 0.708882434680439, Test ROC-AUC = 0.5078364610671997\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.6096048653125763, Train ROC-AUC = 0.7489877939224243\n",
            "Val Loss = 0.6579291224479675, Val ROC-AUC = 0.6666666865348816\n",
            "Test Loss = 0.7321148811818693, Test ROC-AUC = 0.5123666524887085\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.6142307221889496, Train ROC-AUC = 0.7489877939224243\n",
            "Val Loss = 0.6086099743843079, Val ROC-AUC = 1.0\n",
            "Test Loss = 0.754817534559451, Test ROC-AUC = 0.5031808018684387\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.6210319995880127, Train ROC-AUC = 0.76113361120224\n",
            "Val Loss = 0.6551952958106995, Val ROC-AUC = 0.6666666865348816\n",
            "Test Loss = 0.7435541598560711, Test ROC-AUC = 0.48999908566474915\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.6036462485790253, Train ROC-AUC = 0.7541666626930237\n",
            "Val Loss = 0.5130035281181335, Val ROC-AUC = 1.0\n",
            "Test Loss = 0.7583738822525683, Test ROC-AUC = 0.49590086936950684\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.6483575105667114, Train ROC-AUC = 0.5870445966720581\n",
            "Val Loss = 0.8653436899185181, Val ROC-AUC = 0.0\n",
            "Test Loss = 0.7143238588643912, Test ROC-AUC = 0.49197250604629517\n",
            "\n",
            "best epoch = 274\n",
            "Train Loss = 0.6434019804000854, Train ROC-AUC = 0.7843137383460999\n",
            "Val Loss = 0.7083143591880798, Val ROC-AUC = 0.1666666716337204\n",
            "Test Loss = 0.7141590828712756, Test ROC-AUC = 0.5070592761039734\n",
            "\n",
            "best epoch = 151\n",
            "Train Loss = 0.6235466003417969, Train ROC-AUC = 0.829365074634552\n",
            "Val Loss = 0.6669730544090271, Val ROC-AUC = 0.6666666865348816\n",
            "Test Loss = 0.7075855071171404, Test ROC-AUC = 0.49772173166275024\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.6740998029708862, Train ROC-AUC = 0.615686297416687\n",
            "Val Loss = 0.6504494547843933, Val ROC-AUC = 0.6666666865348816\n",
            "Test Loss = 0.7070976510977212, Test ROC-AUC = 0.5103361010551453\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.6688060164451599, Train ROC-AUC = 0.6865079402923584\n",
            "Val Loss = 0.6678808331489563, Val ROC-AUC = 0.3333333432674408\n",
            "Test Loss = 0.7052305032270023, Test ROC-AUC = 0.5131354928016663\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.6012349128723145, Train ROC-AUC = 0.800000011920929\n",
            "Val Loss = 0.6789221167564392, Val ROC-AUC = 0.5\n",
            "Test Loss = 0.724892574186904, Test ROC-AUC = 0.4981454610824585\n",
            "\n",
            "best epoch = 350\n",
            "Train Loss = 0.6213383972644806, Train ROC-AUC = 0.7651821970939636\n",
            "Val Loss = 0.6040038466453552, Val ROC-AUC = 0.8333333730697632\n",
            "Test Loss = 0.728592897756412, Test ROC-AUC = 0.5079329013824463\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.6194984316825867, Train ROC-AUC = 0.7363636493682861\n",
            "Val Loss = 0.6252334713935852, Val ROC-AUC = 0.8333333730697632\n",
            "Test Loss = 0.7108403088185734, Test ROC-AUC = 0.49521932005882263\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.6118031740188599, Train ROC-AUC = 0.7374999523162842\n",
            "Val Loss = 0.6081749796867371, Val ROC-AUC = 0.8333333730697632\n",
            "Test Loss = 0.7652986582856589, Test ROC-AUC = 0.4996231198310852\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.6503428518772125, Train ROC-AUC = 0.6291667222976685\n",
            "Val Loss = 0.6341245770454407, Val ROC-AUC = 0.8333333730697632\n",
            "Test Loss = 0.7470984908338553, Test ROC-AUC = 0.49807682633399963\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.5889536440372467, Train ROC-AUC = 0.800000011920929\n",
            "Val Loss = 0.671814501285553, Val ROC-AUC = 0.3333333432674408\n",
            "Test Loss = 0.7307046339534723, Test ROC-AUC = 0.49506470561027527\n",
            "\n",
            "best epoch = 445\n",
            "Train Loss = 0.6242004930973053, Train ROC-AUC = 0.7813764810562134\n",
            "Val Loss = 0.6600145697593689, Val ROC-AUC = 0.6666666865348816\n",
            "Test Loss = 0.7360288784526788, Test ROC-AUC = 0.49581074714660645\n",
            "\n",
            "0.66666675 0.50117\n",
            "Running command with l=1, n=50, d=16\n",
            "Running: python3 train_random.py -b 16 --lr 0.0001 --epochs 500 --hidden_size 16 -l 1 -n 50 --n_test 5000 -d 16 -r 2 --optim adamw --seed 42 --save_path ./out/ --experiment N1000_dnl\n",
            "device:  cuda\n",
            "best epoch = 0\n",
            "Train Loss = 0.6293611228466034, Train ROC-AUC = 0.698039174079895\n",
            "Val Loss = 0.7232206463813782, Val ROC-AUC = 0.5\n",
            "Test Loss = 0.7039472538823137, Test ROC-AUC = 0.500819206237793\n",
            "\n",
            "best epoch = 498\n",
            "Train Loss = 0.6710297167301178, Train ROC-AUC = 0.6587302088737488\n",
            "Val Loss = 0.664358913898468, Val ROC-AUC = 0.5\n",
            "Test Loss = 0.7027428776692277, Test ROC-AUC = 0.4986627995967865\n",
            "\n",
            "best epoch = 0\n",
            "Train Loss = 0.6523978114128113, Train ROC-AUC = 0.7215685844421387\n",
            "Val Loss = 0.7087868452072144, Val ROC-AUC = 0.5\n",
            "Test Loss = 0.7027921067259182, Test ROC-AUC = 0.4939705729484558\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.6616694629192352, Train ROC-AUC = 0.6904761791229248\n",
            "Val Loss = 0.6881256699562073, Val ROC-AUC = 0.6666666865348816\n",
            "Test Loss = 0.7015165928453683, Test ROC-AUC = 0.4905649721622467\n",
            "\n",
            "best epoch = 0\n",
            "Train Loss = 0.6611136496067047, Train ROC-AUC = 0.658730149269104\n",
            "Val Loss = 0.6218860149383545, Val ROC-AUC = 0.6666666269302368\n",
            "Test Loss = 0.7096433921363026, Test ROC-AUC = 0.5076659917831421\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.6790256500244141, Train ROC-AUC = 0.5882352590560913\n",
            "Val Loss = 0.6425365805625916, Val ROC-AUC = 0.8333333730697632\n",
            "Test Loss = 0.6973173500249942, Test ROC-AUC = 0.4979538321495056\n",
            "\n",
            "best epoch = 0\n",
            "Train Loss = 0.6665916740894318, Train ROC-AUC = 0.65234375\n",
            "Val Loss = 0.612424373626709, Val ROC-AUC = 0.8333333730697632\n",
            "Test Loss = 0.7252330473436716, Test ROC-AUC = 0.4908451437950134\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.67529296875, Train ROC-AUC = 0.7229437232017517\n",
            "Val Loss = 0.7160724997520447, Val ROC-AUC = 0.3333333432674408\n",
            "Test Loss = 0.6973207539643723, Test ROC-AUC = 0.4978015720844269\n",
            "\n",
            "best epoch = 0\n",
            "Train Loss = 0.6559032201766968, Train ROC-AUC = 0.6785714626312256\n",
            "Val Loss = 0.74736088514328, Val ROC-AUC = 0.1666666716337204\n",
            "Test Loss = 0.7064700261853374, Test ROC-AUC = 0.490148663520813\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.6882092356681824, Train ROC-AUC = 0.6309523582458496\n",
            "Val Loss = 0.6497051119804382, Val ROC-AUC = 1.0\n",
            "Test Loss = 0.6982623957597409, Test ROC-AUC = 0.4930570125579834\n",
            "\n",
            "best epoch = 365\n",
            "Train Loss = 0.6390088200569153, Train ROC-AUC = 0.7103174924850464\n",
            "Val Loss = 0.6986302733421326, Val ROC-AUC = 0.5\n",
            "Test Loss = 0.7039038165689657, Test ROC-AUC = 0.49432891607284546\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.6627911329269409, Train ROC-AUC = 0.7575757503509521\n",
            "Val Loss = 0.6970266699790955, Val ROC-AUC = 0.5\n",
            "Test Loss = 0.6981453935559184, Test ROC-AUC = 0.5060452222824097\n",
            "\n",
            "best epoch = 152\n",
            "Train Loss = 0.676980048418045, Train ROC-AUC = 0.6352940797805786\n",
            "Val Loss = 0.6995365023612976, Val ROC-AUC = 0.6666666865348816\n",
            "Test Loss = 0.7066904405435435, Test ROC-AUC = 0.48818618059158325\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.6568275988101959, Train ROC-AUC = 0.714285671710968\n",
            "Val Loss = 0.6363280415534973, Val ROC-AUC = 0.8333333730697632\n",
            "Test Loss = 0.7001178611200839, Test ROC-AUC = 0.4977705180644989\n",
            "\n",
            "best epoch = 484\n",
            "Train Loss = 0.6782086193561554, Train ROC-AUC = 0.6078431606292725\n",
            "Val Loss = 0.6560627818107605, Val ROC-AUC = 0.8333333730697632\n",
            "Test Loss = 0.7017455198132573, Test ROC-AUC = 0.4956471025943756\n",
            "\n",
            "best epoch = 0\n",
            "Train Loss = 0.6615951061248779, Train ROC-AUC = 0.6328125\n",
            "Val Loss = 0.5892648100852966, Val ROC-AUC = 1.0\n",
            "Test Loss = 0.7069630946595067, Test ROC-AUC = 0.5123679637908936\n",
            "\n",
            "best epoch = 0\n",
            "Train Loss = 0.6129964888095856, Train ROC-AUC = 0.8156862854957581\n",
            "Val Loss = 0.7373013496398926, Val ROC-AUC = 0.3333333134651184\n",
            "Test Loss = 0.7007824652872908, Test ROC-AUC = 0.49340757727622986\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.6400437355041504, Train ROC-AUC = 0.8097165822982788\n",
            "Val Loss = 0.6482934355735779, Val ROC-AUC = 0.6666666865348816\n",
            "Test Loss = 0.7012033932886946, Test ROC-AUC = 0.49897319078445435\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.678573727607727, Train ROC-AUC = 0.6328125\n",
            "Val Loss = 0.6588484644889832, Val ROC-AUC = 0.8333333730697632\n",
            "Test Loss = 0.6952847990745934, Test ROC-AUC = 0.5013922452926636\n",
            "\n",
            "best epoch = 371\n",
            "Train Loss = 0.6596995890140533, Train ROC-AUC = 0.64682537317276\n",
            "Val Loss = 0.6597996950149536, Val ROC-AUC = 1.0\n",
            "Test Loss = 0.7016519728940896, Test ROC-AUC = 0.48693448305130005\n",
            "\n",
            "best epoch = 481\n",
            "Train Loss = 0.6750322878360748, Train ROC-AUC = 0.6791666746139526\n",
            "Val Loss = 0.7074658274650574, Val ROC-AUC = 0.8333333730697632\n",
            "Test Loss = 0.7085161974635749, Test ROC-AUC = 0.49448487162590027\n",
            "\n",
            "best epoch = 158\n",
            "Train Loss = 0.6478808522224426, Train ROC-AUC = 0.69140625\n",
            "Val Loss = 0.7324399948120117, Val ROC-AUC = 0.3333333134651184\n",
            "Test Loss = 0.700961965912828, Test ROC-AUC = 0.5029895305633545\n",
            "\n",
            "best epoch = 496\n",
            "Train Loss = 0.6410127282142639, Train ROC-AUC = 0.8039215207099915\n",
            "Val Loss = 0.6614425778388977, Val ROC-AUC = 0.6666666269302368\n",
            "Test Loss = 0.7021436064768904, Test ROC-AUC = 0.5002429485321045\n",
            "\n",
            "best epoch = 147\n",
            "Train Loss = 0.668381929397583, Train ROC-AUC = 0.6470587849617004\n",
            "Val Loss = 0.6729729771614075, Val ROC-AUC = 1.0\n",
            "Test Loss = 0.6972025720456156, Test ROC-AUC = 0.488763689994812\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.6610579490661621, Train ROC-AUC = 0.7490196228027344\n",
            "Val Loss = 0.6236947774887085, Val ROC-AUC = 0.8333333730697632\n",
            "Test Loss = 0.7001733240989831, Test ROC-AUC = 0.4954986870288849\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.6658706665039062, Train ROC-AUC = 0.6328125\n",
            "Val Loss = 0.6518699526786804, Val ROC-AUC = 0.6666666865348816\n",
            "Test Loss = 0.716342115744996, Test ROC-AUC = 0.49566563963890076\n",
            "\n",
            "best epoch = 0\n",
            "Train Loss = 0.6703232526779175, Train ROC-AUC = 0.7103173732757568\n",
            "Val Loss = 0.6773048639297485, Val ROC-AUC = 0.5\n",
            "Test Loss = 0.7124487711979558, Test ROC-AUC = 0.5085183382034302\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.6512361764907837, Train ROC-AUC = 0.7686274647712708\n",
            "Val Loss = 0.6952848434448242, Val ROC-AUC = 0.6666666865348816\n",
            "Test Loss = 0.6993632617469032, Test ROC-AUC = 0.49940285086631775\n",
            "\n",
            "best epoch = 0\n",
            "Train Loss = 0.6409030854701996, Train ROC-AUC = 0.7420634627342224\n",
            "Val Loss = 0.6477558016777039, Val ROC-AUC = 1.0\n",
            "Test Loss = 0.6963399380159835, Test ROC-AUC = 0.5064762234687805\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.6734959483146667, Train ROC-AUC = 0.5668016076087952\n",
            "Val Loss = 0.666033923625946, Val ROC-AUC = 0.6666666865348816\n",
            "Test Loss = 0.7031304025040648, Test ROC-AUC = 0.5041904449462891\n",
            "\n",
            "0.6777777 0.49775922\n",
            "Running command with l=1, n=50, d=32\n",
            "Running: python3 train_random.py -b 16 --lr 0.0001 --epochs 500 --hidden_size 16 -l 1 -n 50 --n_test 5000 -d 32 -r 2 --optim adamw --seed 42 --save_path ./out/ --experiment N1000_dnl\n",
            "device:  cuda\n",
            "best epoch = 314\n",
            "Train Loss = 0.6240508556365967, Train ROC-AUC = 0.7411764860153198\n",
            "Val Loss = 0.6589248776435852, Val ROC-AUC = 0.5\n",
            "Test Loss = 0.7144082358089118, Test ROC-AUC = 0.4915936589241028\n",
            "\n",
            "best epoch = 481\n",
            "Train Loss = 0.6315289735794067, Train ROC-AUC = 0.7341269850730896\n",
            "Val Loss = 0.6792170405387878, Val ROC-AUC = 0.6666666865348816\n",
            "Test Loss = 0.7070406029780452, Test ROC-AUC = 0.5003150105476379\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.6024264693260193, Train ROC-AUC = 0.8196078538894653\n",
            "Val Loss = 0.5904002785682678, Val ROC-AUC = 0.8333333730697632\n",
            "Test Loss = 0.7197873499065923, Test ROC-AUC = 0.4977559447288513\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.6523156464099884, Train ROC-AUC = 0.73828125\n",
            "Val Loss = 0.6899883151054382, Val ROC-AUC = 0.8333333730697632\n",
            "Test Loss = 0.7007861480164451, Test ROC-AUC = 0.507347583770752\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.6039693355560303, Train ROC-AUC = 0.79296875\n",
            "Val Loss = 0.6769195795059204, Val ROC-AUC = 0.8333333730697632\n",
            "Test Loss = 0.7283206913417901, Test ROC-AUC = 0.493575781583786\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.6260501742362976, Train ROC-AUC = 0.753036379814148\n",
            "Val Loss = 0.6674986481666565, Val ROC-AUC = 0.5\n",
            "Test Loss = 0.7071013964784031, Test ROC-AUC = 0.5008273720741272\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.6484194099903107, Train ROC-AUC = 0.6904761791229248\n",
            "Val Loss = 0.6448907256126404, Val ROC-AUC = 0.8333333730697632\n",
            "Test Loss = 0.7067084620935848, Test ROC-AUC = 0.49731746315956116\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.6502044498920441, Train ROC-AUC = 0.7063491344451904\n",
            "Val Loss = 0.6337310075759888, Val ROC-AUC = 0.6666666269302368\n",
            "Test Loss = 0.7065034171643729, Test ROC-AUC = 0.49917536973953247\n",
            "\n",
            "best epoch = 2\n",
            "Train Loss = 0.6172132790088654, Train ROC-AUC = 0.7229436635971069\n",
            "Val Loss = 0.7008755803108215, Val ROC-AUC = 0.3333333134651184\n",
            "Test Loss = 0.6954810971650072, Test ROC-AUC = 0.5084989070892334\n",
            "\n",
            "best epoch = 0\n",
            "Train Loss = 0.6068103909492493, Train ROC-AUC = 0.7896825671195984\n",
            "Val Loss = 0.68956059217453, Val ROC-AUC = 0.6666666269302368\n",
            "Test Loss = 0.6943673335325223, Test ROC-AUC = 0.5070594549179077\n",
            "\n",
            "best epoch = 0\n",
            "Train Loss = 0.6366437673568726, Train ROC-AUC = 0.7208333015441895\n",
            "Val Loss = 0.7777345776557922, Val ROC-AUC = 0.1666666716337204\n",
            "Test Loss = 0.7025277504144004, Test ROC-AUC = 0.5078712105751038\n",
            "\n",
            "best epoch = 499\n",
            "Train Loss = 0.6342923641204834, Train ROC-AUC = 0.76113361120224\n",
            "Val Loss = 0.6299339532852173, Val ROC-AUC = 1.0\n",
            "Test Loss = 0.7118231673210192, Test ROC-AUC = 0.4979363977909088\n",
            "\n",
            "best epoch = 1\n",
            "Train Loss = 0.619115799665451, Train ROC-AUC = 0.8156862258911133\n",
            "Val Loss = 0.7238476872444153, Val ROC-AUC = 0.5\n",
            "Test Loss = 0.7086201544386891, Test ROC-AUC = 0.49897825717926025\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import itertools\n",
        "\n",
        "# Define your lists of variables\n",
        "list_l = [1, 32]  # Replace with actual values\n",
        "list_n = [50, 100, 200, 400, 800]\n",
        "list_d = [8, 16, 32, 64]\n",
        "\n",
        "# Iterate over all combinations of $l, $n, and $d\n",
        "for l, n, d in itertools.product(list_l, list_n, list_d):\n",
        "    # Run your command with the variables\n",
        "    # For example, if the command is a Python function, call it directly\n",
        "    print(f\"Running command with l={l}, n={n}, d={d}\")\n",
        "    # command_function(l, n, d)\n",
        "\n",
        "    # If it's a shell command, you can use `!` to execute it\n",
        "    # For example:\n",
        "    # !echo \"Running command with l={l}, n={n}, d={d}\"\n",
        "    command = f\"python3 train_random.py -b 16 --lr 0.0001 --epochs 500 --hidden_size 16 -l {l} -n {n} --n_test 5000 -d {d} -r 2 --optim adamw --seed 42 --save_path ./out/ --experiment N1000_dnl\"\n",
        "    print(f\"Running: {command}\")\n",
        "    !{command}"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}